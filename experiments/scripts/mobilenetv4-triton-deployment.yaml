apiVersion: v1
kind: Namespace
metadata:
  name: workloads
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mobilenetv4-model-pvc
  namespace: workloads
spec:
  accessModes:
    - ReadWriteOnce # Or ReadOnlyMany if multiple Triton instances might read from it, though usually 1 PVC per instance or use ReadWriteOnce.
  resources:
    requests:
      storage: 5Gi # Adjust based on your model(s) size
  # storageClassName: microk8s-hostpath # If you need a specific storage class in MicroK8s and it's not the default
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: mobilenetv4-config-pbtxt-cm
  namespace: workloads
data:
  config.pbtxt: |
    name: "mobilenetv4"
    platform: "onnxruntime_onnx" # Or "tensorflow_savedmodel" or "tensorrt_plan"
    max_batch_size: 0 # 0 means dynamic batching is supported by the model and Triton's scheduler
    input [
      {
        name: "input_tensor_name" # Replace with actual input tensor name
        data_type: TYPE_FP32 # Replace with actual data type
        dims: [ -1, 3, 224, 224 ] # Replace with actual dimensions (e.g., -1 for batch, C, H, W)
      }
    ]
    output [
      {
        name: "output_tensor_name" # Replace with actual output tensor name
        data_type: TYPE_FP32 # Replace with actual data type
        dims: [ -1, 1000 ] # Replace with actual dimensions (e.g., -1 for batch, num_classes)
      }
    ]
    # instance_group [ { kind: KIND_GPU } ] # Uncomment and configure if you want to specify GPU instances
    # dynamic_batching { preferred_batch_size: [4, 8], max_queue_delay_microseconds: 100 } # Optional: configure dynamic batching
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mobilenetv4-triton-deployment
  namespace: workloads
  labels:
    app: mobilenetv4-triton
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mobilenetv4-triton
  template:
    metadata:
      labels:
        app: mobilenetv4-triton
    spec:
      # Optional: If your MicroK8s node has taints that prevent scheduling, add tolerations
      # tolerations:
      # - key: "key"
      #   operator: "Exists"
      #   effect: "NoSchedule"
      volumes:
        - name: model-storage-pvc
          persistentVolumeClaim:
            claimName: mobilenetv4-model-pvc
        - name: model-config-cm
          configMap:
            name: mobilenetv4-config-pbtxt-cm
        - name: model-repository # emptyDir volume for the combined model repository
          emptyDir: {}
      initContainers:
      - name: populate-model-repository
        image: busybox:latest # Or any image with cp/mkdir
        command: ['/bin/sh', '-c']
        args:
          - |
            echo "Copying model config (config.pbtxt)..."
            mkdir -p /mnt/repository/mobilenetv4
            cp /mnt/config/config.pbtxt /mnt/repository/mobilenetv4/config.pbtxt
            echo "Copying model files (e.g., model.onnx)..."
            # You will need to ensure your actual model file (e.g., model.onnx) is in the PVC
            # at the path mobilenetv4/1/model.onnx relative to the PVC root.
            # Example: if PVC is mounted at /mnt/pvc_models, then model is at /mnt/pvc_models/mobilenetv4/1/model.onnx
            # This init container would then copy it:
            if [ -d /mnt/pvc_models/mobilenetv4 ]; then
              echo "Model directory found in PVC, copying..."
              cp -r /mnt/pvc_models/mobilenetv4 /mnt/repository/
            else
              echo "WARNING: Model directory 'mobilenetv4' not found in PVC /mnt/pvc_models/"
              echo "Please ensure your model (e.g. mobilenetv4/1/model.onnx) is in the PVC."
              # Create a dummy structure so Triton doesn't fail immediately if PVC is empty
              mkdir -p /mnt/repository/mobilenetv4/1
              echo "This is a placeholder model file." > /mnt/repository/mobilenetv4/1/placeholder.txt
            fi
            echo "Model repository population complete."
            ls -R /mnt/repository
        volumeMounts:
          - name: model-storage-pvc
            mountPath: /mnt/pvc_models # Where the PVC is mounted
          - name: model-config-cm
            mountPath: /mnt/config # Where config.pbtxt is mounted
          - name: model-repository # The target emptyDir for combined repo
            mountPath: /mnt/repository
      containers:
      - name: triton-inference-server
        # Check NVIDIA NGC for the latest recommended Triton image tag for general use (e.g., includes ONNX, TF, TensorRT backends)
        # Example tag: nvcr.io/nvidia/tritonserver:24.04-py3 (verify this)
        image: nvcr.io/nvidia/tritonserver:24.04-py3
        command: ["tritonserver"]
        args:
          - --model-repository=/models # This is the emptyDir populated by the init container
          - --strict-model-config=false # Allows Triton to start even if a model initially fails to load
          # - --log-verbose=1 # Uncomment for more detailed logs
        resources:
          limits:
            nvidia.com/gpu: 1
          requests:
            nvidia.com/gpu: 1
        ports:
        - containerPort: 8000
          name: http
        - containerPort: 8001
          name: grpc
        - containerPort: 8002
          name: metrics
        readinessProbe:
          httpGet:
            path: /v2/health/ready
            port: http
          initialDelaySeconds: 20
          periodSeconds: 5
          timeoutSeconds: 2
          failureThreshold: 5
        livenessProbe:
          httpGet:
            path: /v2/health/live
            port: http
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 2
          failureThreshold: 3
        volumeMounts:
          - name: model-repository # Mount the populated model repository from emptyDir
            mountPath: /models
---
apiVersion: v1
kind: Service
metadata:
  name: mobilenetv4-triton-svc
  namespace: workloads
  labels:
    app: mobilenetv4-triton
spec:
  selector:
    app: mobilenetv4-triton
  ports:
  - name: http
    port: 8000
    targetPort: http
  - name: grpc
    port: 8001
    targetPort: grpc
  - name: metrics
    port: 8002
    targetPort: metrics
  type: ClusterIP # Start with ClusterIP, change to LoadBalancer if external access needed via MetalLB 